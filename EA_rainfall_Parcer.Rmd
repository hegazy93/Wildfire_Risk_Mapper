---
title: "MetOffice DataPoint Parser"
author: "Abdelrahman Ibrahim"
date: "2023-11-06"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Load packages 

```{r, include=TRUE}
require(httr)
require(jsonlite)
require(sf)
require(tidyverse)
require(purrr)
```

## Get data

measurement stations: 

```{r , include=TRUE}
stations <- readr::read_csv("http://environment.data.gov.uk/flood-monitoring/id/stations.csv", show_col_types = FALSE) %>% 
  filter(parameter == "rainfall")%>%
  filter(stationReference != 'Not_Specified') %>%
  select(stationReference, lat, long)
head(stations)
```

Get the hourly observation data:

```{r , include=TRUE}
list_of_files <- list.files(path = r"(1_raw_data\Climate Data\EA_rainfall_archive)",
                            recursive = TRUE,
                            pattern = "\\.csv$",
                            full.names = TRUE)

rainfall <- readr::read_csv(list_of_files, col_types = cols(stationReference = col_character(), date = col_date(), value =col_double())) %>% 
  filter(parameter == "rainfall") %>%
  filter(stationReference != 'Not_Specified') %>%
  select(dateTime, date, stationReference, value) %>%
  group_by(date, stationReference) %>%
  summarise(daily_rainfall = sum(value)) %>%
  full_join(stations, 
           by = c("stationReference")) %>%
  drop_na()

rainfall
```

## Append the daily rainfall database

```{r , include=TRUE}
write.table(rainfall, (r"(2_processed_data\ea_daily_rainfall.csv)"), sep = ",", row.names = FALSE)
```

## Create a surface of daily average observations using IDW interpolation

```{r , include=TRUE}

```

